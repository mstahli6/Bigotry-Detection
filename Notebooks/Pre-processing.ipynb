{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61fe8e53",
   "metadata": {},
   "source": [
    "# Pre-Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643426af",
   "metadata": {},
   "source": [
    "Final Imputing and Dropping\n",
    "\n",
    "[Training set, Validation Set, and Final Test](#Training-set,-Validation-Set,-and-Final-Test)\n",
    "\n",
    "[Numeric Scaling](#Numeric-Scaling)\n",
    " - Note the Count Vectorization takes place in the Modelling Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddda5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e2f75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigotry</th>\n",
       "      <th>directed</th>\n",
       "      <th>sentiment_comment</th>\n",
       "      <th>sentiment_topic</th>\n",
       "      <th>overall_sentiment_score</th>\n",
       "      <th>ups</th>\n",
       "      <th>dal</th>\n",
       "      <th>word_count</th>\n",
       "      <th>up_low_ratio</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>disgust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>anger</th>\n",
       "      <th>sad</th>\n",
       "      <th>happy</th>\n",
       "      <th>fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.688598</td>\n",
       "      <td>13</td>\n",
       "      <td>8.38</td>\n",
       "      <td>16</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>['yeah', 'man', 'back', 'then', 'o', 'is', 'di...</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.017550</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>0.024791</td>\n",
       "      <td>0.040254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.413420</td>\n",
       "      <td>8</td>\n",
       "      <td>11.38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>['gt', 'i', 'just', 'extended', 'for', 'a', 'y...</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.045918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.880108</td>\n",
       "      <td>2</td>\n",
       "      <td>8.18</td>\n",
       "      <td>12</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>['the', 'hell', 'that', 'many', 'people', 'get...</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.013686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.160947</td>\n",
       "      <td>2</td>\n",
       "      <td>10.09</td>\n",
       "      <td>41</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>['worked', 'perfectly', 'im', 'glad', 'to', 'h...</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.018059</td>\n",
       "      <td>0.013498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1.269243</td>\n",
       "      <td>2</td>\n",
       "      <td>7.04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>['this', 'is', 'so', 'bullshit', 'why', 'doe',...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bigotry  directed sentiment_comment sentiment_topic  \\\n",
       "1    False      True           neutral         neutral   \n",
       "2    False      True           neutral         neutral   \n",
       "3    False      True           neutral         neutral   \n",
       "4    False      True          positive        positive   \n",
       "5    False      True          positive        positive   \n",
       "\n",
       "   overall_sentiment_score  ups    dal  word_count  up_low_ratio  \\\n",
       "1                 0.688598   13   8.38          16      0.045455   \n",
       "2                -0.413420    8  11.38          38      0.035211   \n",
       "3                -0.880108    2   8.18          12      0.035088   \n",
       "4                 3.160947    2  10.09          41      0.043269   \n",
       "5                -1.269243    2   7.04          10      0.044444   \n",
       "\n",
       "                                     text_lemmatized   disgust  surprise  \\\n",
       "1  ['yeah', 'man', 'back', 'then', 'o', 'is', 'di...  0.015762  0.026123   \n",
       "2  ['gt', 'i', 'just', 'extended', 'for', 'a', 'y...  0.005102  0.035714   \n",
       "3  ['the', 'hell', 'that', 'many', 'people', 'get...  0.007692  0.010889   \n",
       "4  ['worked', 'perfectly', 'im', 'glad', 'to', 'h...  0.001270  0.017361   \n",
       "5  ['this', 'is', 'so', 'bullshit', 'why', 'doe',...  0.000002  0.000046   \n",
       "\n",
       "    neutral     anger       sad     happy      fear  \n",
       "1  0.003467  0.017550  0.032248  0.024791  0.040254  \n",
       "2  0.005102  0.025510  0.045918  0.005102  0.045918  \n",
       "3  0.000100  0.068831  0.027073  0.015085  0.013686  \n",
       "4  0.000836  0.007215  0.016621  0.018059  0.013498  \n",
       "5  0.000736  0.000042  0.000046  0.000553  0.000013  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/df_post_eda.csv',  index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc2649",
   "metadata": {},
   "source": [
    "There were 515 missing rows for the emotion sensor scores. \n",
    "I decided to fill with `0`. No missing emotion sensor scores coincided with bigotry == True. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8fd55",
   "metadata": {},
   "source": [
    "#### Impute zero for missing emotion scores, drop unnecessary comments, rename the emotion words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f898c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc_onlyb = df\n",
    "df_proc_onlyb[['disgust', 'surprise', 'neutral', 'anger', 'sad',\n",
    "       'happy', 'fear']] = df_proc_onlyb[['disgust', 'surprise', 'neutral', 'anger', 'sad',\n",
    "       'happy', 'fear']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e54eb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc_onlyb = df_proc_onlyb.drop(columns=['sentiment_comment', 'sentiment_topic', 'overall_sentiment_score', 'directed'])\n",
    "df_proc_onlyb = df_proc_onlyb.rename(columns={'disgust':'disgust_x', 'surprise':'surprise_x', 'neutral':'neutral_x', 'anger':'anger_x', 'sad':'sad_x',\n",
    "       'happy':'happy_x', 'fear':'fear_x'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5ed4e",
   "metadata": {},
   "source": [
    "Had three rows left with missing text - must have been without words. Drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0867920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8925, 13)\n",
      "(8922, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_proc_onlyb.shape)\n",
    "df_proc_onlyb = df_proc_onlyb.dropna()\n",
    "print(df_proc_onlyb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febb29dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigotry</th>\n",
       "      <th>ups</th>\n",
       "      <th>dal</th>\n",
       "      <th>word_count</th>\n",
       "      <th>up_low_ratio</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>disgust_x</th>\n",
       "      <th>surprise_x</th>\n",
       "      <th>neutral_x</th>\n",
       "      <th>anger_x</th>\n",
       "      <th>sad_x</th>\n",
       "      <th>happy_x</th>\n",
       "      <th>fear_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>8.38</td>\n",
       "      <td>16</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>['yeah', 'man', 'back', 'then', 'o', 'is', 'di...</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.017550</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>0.024791</td>\n",
       "      <td>0.040254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>11.38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>['gt', 'i', 'just', 'extended', 'for', 'a', 'y...</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.045918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>8.18</td>\n",
       "      <td>12</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>['the', 'hell', 'that', 'many', 'people', 'get...</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.013686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>10.09</td>\n",
       "      <td>41</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>['worked', 'perfectly', 'im', 'glad', 'to', 'h...</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.018059</td>\n",
       "      <td>0.013498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>7.04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>['this', 'is', 'so', 'bullshit', 'why', 'doe',...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bigotry  ups    dal  word_count  up_low_ratio  \\\n",
       "1    False   13   8.38          16      0.045455   \n",
       "2    False    8  11.38          38      0.035211   \n",
       "3    False    2   8.18          12      0.035088   \n",
       "4    False    2  10.09          41      0.043269   \n",
       "5    False    2   7.04          10      0.044444   \n",
       "\n",
       "                                     text_lemmatized  disgust_x  surprise_x  \\\n",
       "1  ['yeah', 'man', 'back', 'then', 'o', 'is', 'di...   0.015762    0.026123   \n",
       "2  ['gt', 'i', 'just', 'extended', 'for', 'a', 'y...   0.005102    0.035714   \n",
       "3  ['the', 'hell', 'that', 'many', 'people', 'get...   0.007692    0.010889   \n",
       "4  ['worked', 'perfectly', 'im', 'glad', 'to', 'h...   0.001270    0.017361   \n",
       "5  ['this', 'is', 'so', 'bullshit', 'why', 'doe',...   0.000002    0.000046   \n",
       "\n",
       "   neutral_x   anger_x     sad_x   happy_x    fear_x  \n",
       "1   0.003467  0.017550  0.032248  0.024791  0.040254  \n",
       "2   0.005102  0.025510  0.045918  0.005102  0.045918  \n",
       "3   0.000100  0.068831  0.027073  0.015085  0.013686  \n",
       "4   0.000836  0.007215  0.016621  0.018059  0.013498  \n",
       "5   0.000736  0.000042  0.000046  0.000553  0.000013  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc_onlyb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50be53",
   "metadata": {},
   "source": [
    "### Training set, Validation Set, and Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f577dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_proc_onlyb.drop(columns='bigotry')\n",
    "y = df_proc_onlyb['bigotry']\n",
    "\n",
    "X_model, X_test, y_model, y_test = train_test_split(X, y, test_size=0.2, random_state=26, stratify=y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff93488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size=0.2, random_state=26, stratify=y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f6187",
   "metadata": {},
   "source": [
    "### Numeric Scaling\n",
    "Used Normalizer. Could have considered something stronger, like Power Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6deb6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_num_bigotry (X_train, X_test):\n",
    "    #takes in X_train, X_test, fits and transforms with MinMaxScaler\n",
    "    #Returns train and test scaled \n",
    "  \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "   \n",
    "    MM_scaler = MinMaxScaler()\n",
    "    numeric_cols = X_train.select_dtypes(include='number').columns\n",
    "\n",
    "    X_train_scaled = X_train\n",
    "    X_test_scaled = X_test\n",
    "\n",
    "    #Fit only on training \n",
    "    MM_scaler.fit(X_train[numeric_cols])\n",
    "  \n",
    "    X_train_scaled[numeric_cols] = MM_scaler.transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = MM_scaler.transform(X_test[numeric_cols])\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a58b96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_val_scaled = scale_num_bigotry(X_train, X_val)\n",
    "X_model_scaled, X_test_scaled = scale_num_bigotry(X_model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8466992b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ups</th>\n",
       "      <th>dal</th>\n",
       "      <th>word_count</th>\n",
       "      <th>up_low_ratio</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>disgust_x</th>\n",
       "      <th>surprise_x</th>\n",
       "      <th>neutral_x</th>\n",
       "      <th>anger_x</th>\n",
       "      <th>sad_x</th>\n",
       "      <th>happy_x</th>\n",
       "      <th>fear_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>0.020278</td>\n",
       "      <td>0.027289</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>['my', 'question', 'is', 'why', 'the', 'hell',...</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.021392</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.023670</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>['hello', 'lady', 'why', 'doe', 'it', 'not', '...</td>\n",
       "      <td>0.116940</td>\n",
       "      <td>0.180855</td>\n",
       "      <td>0.050729</td>\n",
       "      <td>0.249121</td>\n",
       "      <td>0.431424</td>\n",
       "      <td>0.139643</td>\n",
       "      <td>0.094614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6323</th>\n",
       "      <td>0.020278</td>\n",
       "      <td>0.211989</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>['le', 'sighhttpiimgurcomgif']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.044095</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>['ha', 'gleaned', 'that', 'from', 'your', 'com...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9578</th>\n",
       "      <td>0.020278</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>['doe', 'it', 'still', 'use', 'underneath', 'f...</td>\n",
       "      <td>0.028498</td>\n",
       "      <td>0.244707</td>\n",
       "      <td>0.027259</td>\n",
       "      <td>0.211970</td>\n",
       "      <td>0.238071</td>\n",
       "      <td>0.258791</td>\n",
       "      <td>0.149525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ups       dal  word_count  up_low_ratio  \\\n",
       "4810  0.020278  0.027289    0.007385      0.019608   \n",
       "980   0.020833  0.023670    0.005538      0.062500   \n",
       "6323  0.020278  0.211989    0.000615      0.107143   \n",
       "700   0.020556  0.044095    0.003692      0.062500   \n",
       "9578  0.020278  0.034278    0.022154      0.068750   \n",
       "\n",
       "                                        text_lemmatized  disgust_x  \\\n",
       "4810  ['my', 'question', 'is', 'why', 'the', 'hell',...   0.000159   \n",
       "980   ['hello', 'lady', 'why', 'doe', 'it', 'not', '...   0.116940   \n",
       "6323                     ['le', 'sighhttpiimgurcomgif']   0.000000   \n",
       "700   ['ha', 'gleaned', 'that', 'from', 'your', 'com...   0.000000   \n",
       "9578  ['doe', 'it', 'still', 'use', 'underneath', 'f...   0.028498   \n",
       "\n",
       "      surprise_x  neutral_x   anger_x     sad_x   happy_x    fear_x  \n",
       "4810    0.001088   0.021392  0.000437  0.001057  0.001371  0.001070  \n",
       "980     0.180855   0.050729  0.249121  0.431424  0.139643  0.094614  \n",
       "6323    0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "700     0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9578    0.244707   0.027259  0.211970  0.238071  0.258791  0.149525  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0acd32",
   "metadata": {},
   "source": [
    "***Save all as csv's.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "194cfeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/X_for_vector.csv')\n",
    "X_train_scaled.to_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/X_train_scaled_ob.csv') \n",
    "X_val_scaled.to_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/X_val_scaled_ob.csv') \n",
    "y_train.to_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/y_train_ob.csv') \n",
    "y_val.to_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/y_val_ob.csv') \n",
    "y_model.to_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/y_model_ob.csv') \n",
    "X_test_scaled.to_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/X_test__scaled_ob.csv')\n",
    "X_model_scaled.to_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/X_final_train_scaled_ob.csv') \n",
    "y_test.to_csv(r'/Users/michelstahli/Spring 2022 (Bootcamp+)/Jupyter Notebook CSVs/y_test_ob.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
